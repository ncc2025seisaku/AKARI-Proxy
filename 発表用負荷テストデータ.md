# 発表用負荷テストデータ（デモサーバー: 127.0.0.1, v2+Brotli応答）
- 実行コマンド: `uv run --python 3.11 python loadtest/disaster_suite.py --demo-server --no-event-log --host 127.0.0.1 --port 0`
- すべてローカルで実行。詳細ログ: `logs/disaster_suite_summary.json`, `logs/disaster_suite_history.jsonl`

## シナリオ別結果（成功/総リクエスト, timeout数, 平均応答時間）
- ベースライン: 80/80 成功, timeout 0, 平均0.009s
- 遅延3000ms+ロス20%: 164/200 成功, timeout 36, 平均0.165s
- ジッター350ms相当: 200/200 成功, timeout 0, 平均0.174s
- ロス25%: 162/220 成功, timeout 58, 平均0.008s
- バースト高並列: 765/800 成功, timeout 35, 平均0.029s
- 中負荷持続: 400/400 成功, timeout 0, 平均0.043s
- 断続ドロップ: 126/150 成功, timeout 24, 平均0.002s
- 強フラップ: 182/200 成功, timeout 18, 平均0.013s
- フラップ緩和（再送強化）: 173/200 成功, timeout 27, 平均0.010s
- MTU揺れ近似: 231/240 成功, timeout 9, 平均0.030s
- 巨大レスポンス10MB: Brotli圧縮・チャンク分割で 3/10 成功, timeout 7, 平均0.316s（超大容量はタイムアウト寄り）
- 3000本相当ロード: 2938/3000 成功, timeout 62, 平均0.096s

## ひとこと
- 受信ごとにタイムアウト延長する仕様は継続。遅い応答も拾いやすいが、巨大レスポンスでは未完が増えたのでタイムアウト/再送間隔の再調整余地あり。
- フラップや高遅延・高ロスでも大半が完走。timeoutは再送間隔や全体タイムアウトを少し伸ばすとさらに下げられる見込み。
- バースト/多並列は高速に処理。極端条件では成功数とtimeoutのバランスを環境に合わせてチューニング可能。
